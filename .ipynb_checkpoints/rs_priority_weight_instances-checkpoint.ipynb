{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9ff368",
   "metadata": {},
   "source": [
    "## Ridesharing Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125a46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from pymoo.core.problem import Problem, ElementwiseProblem\n",
    "from pymoo.core.population import Population\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.core.repair import Repair\n",
    "from pymoo.core.crossover import Crossover\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.selection import Selection\n",
    "from pymoo.util.misc import random_permuations\n",
    "from pymoo.core.duplicate import ElementwiseDuplicateElimination\n",
    "from pymoo.factory import get_reference_directions, get_selection\n",
    "from pymoo.core.individual import Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33512ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vehicle Type Fuel Capacity Emission Cost\n",
    "vehicle_types = {\n",
    "    1: {\n",
    "        'type': 'mini car',\n",
    "        'fuel': 'petrol',\n",
    "        'capacity': '1',\n",
    "        'emission': np.array([1, 2*0.9]),\n",
    "        'cost': 1\n",
    "    },\n",
    "    3: {\n",
    "        'type': 'standard car',\n",
    "        'fuel': 'electric',\n",
    "        'capacity': '3',\n",
    "        'emission': np.array([1.0/3.4, 2.0*0.9/3.4, \n",
    "                              3.0*0.9**2/3.4, 4.0*0.9**3/3.4]),\n",
    "        'cost': 3\n",
    "    },\n",
    "    6: {\n",
    "        'type': 'standard car',\n",
    "        'fuel': 'petrol',\n",
    "        'capacity': '6',\n",
    "        'emission': np.array([1, 2*0.9, 3*0.9**2, 4*0.9**3, \n",
    "                              5*0.9**4, 6*0.9**5, 7*0.9**6]),\n",
    "        'cost': 6\n",
    "    },\n",
    "    9: {\n",
    "        'type': 'family car',\n",
    "        'fuel': 'petrol',\n",
    "        'capacity': '10',\n",
    "        'emission': np.array([1, 2*0.9, 3*0.9**2, 4*0.9**3, 5*0.9**4, \n",
    "                              6*0.9**5, 7*0.9**6, 8*0.9**7, 9*0.9**8, 10*0.9**9, 11*0.9**10]),\n",
    "        'cost': 10\n",
    "    },\n",
    "    30: {\n",
    "        'type': 'coach',\n",
    "        'fuel': 'petrol',\n",
    "        'capacity': '30',\n",
    "        'emission': np.array([1/4, 2/4*0.9, 3/4*0.9**2, 4/4*0.9**3, 5/4*0.9**4, 6/4*0.9**5, \n",
    "                              7/4*0.9**6, 8/4*0.9**7, 9/4*0.9**8, 10/4*0.9**9, 11/4*0.9**10, \n",
    "                              12/4*0.9**11, 13/4*0.9**12, 14/4*0.9**13, 15/4*0.9**14, 16/4*0.9**15, \n",
    "                              17/4*0.9**16, 18/4*0.9**17, 19/4*0.9**18, 20/4*0.9**19, 21/4*0.9**20, \n",
    "                              22/4*0.9**21, 23/4*0.9**22, 24/4*0.9**23, 25/4*0.9**24, 26/4*0.9**25, \n",
    "                              27/4*0.9**26, 28/4*0.9**27, 29/4*0.9**28, 30/4*0.9**29, 31/4*0.9**30]),\n",
    "        'cost': 30\n",
    "    },\n",
    "    60: {\n",
    "        'type': 'coach',\n",
    "        'fuel': 'petrol',\n",
    "        'capacity': '30',\n",
    "        'emission': np.array([1/4, 2/4*0.9, 3/4*0.9**2, 4/4*0.9**3, 5/4*0.9**4, 6/4*0.9**5, \n",
    "                              7/4*0.9**6, 8/4*0.9**7, 9/4*0.9**8, 10/4*0.9**9, 11/4*0.9**10, \n",
    "                              12/4*0.9**11, 13/4*0.9**12, 14/4*0.9**13, 15/4*0.9**14, 16/4*0.9**15, \n",
    "                              17/4*0.9**16, 18/4*0.9**17, 19/4*0.9**18, 20/4*0.9**19, 21/4*0.9**20, \n",
    "                              22/4*0.9**21, 23/4*0.9**22, 24/4*0.9**23, 25/4*0.9**24, 26/4*0.9**25, \n",
    "                              27/4*0.9**26, 28/4*0.9**27, 29/4*0.9**28, 30/4*0.9**29, 31/4*0.9**30,\n",
    "                              32/4*0.9**31, 33/4*0.9**32, 34/4*0.9**33, 35/4*0.9**34, 36/4*0.9**35, \n",
    "                              37/4*0.9**36, 38/4*0.9**37, 39/4*0.9**38, 40/4*0.9**39, 41/4*0.9**40, \n",
    "                              42/4*0.9**41, 43/4*0.9**42, 44/4*0.9**43, 45/4*0.9**44, 46/4*0.9**45, \n",
    "                              47/4*0.9**46, 48/4*0.9**47, 49/4*0.9**48, 50/4*0.9**49, 51/4*0.9**50, \n",
    "                              52/4*0.9**51, 53/4*0.9**52, 54/4*0.9**53, 55/4*0.9**54, 56/4*0.9**55, \n",
    "                              57/4*0.9**56, 58/4*0.9**57, 59/4*0.9**58, 60/4*0.9**59, 61/4*0.9**60\n",
    "                             ]),\n",
    "        'cost': 60\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4676b032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,mny,10,10,1\n",
      "2,mny,10,10,3\n",
      "3,mny,10,10,9\n",
      "4,mny,20,10,1\n",
      "5,mny,20,10,3\n",
      "6,mny,20,10,9\n",
      "7,mny,30,10,1\n",
      "8,mny,30,10,3\n",
      "9,mny,30,10,9\n"
     ]
    }
   ],
   "source": [
    "# size down the instance\n",
    "\n",
    "file = 'original_instances/rs-mny-m1k-c3-d6-s10-x1.0.instance'\n",
    "re_path = 'instances_sizedown/'\n",
    "\n",
    "count = 0\n",
    "ins_col = []\n",
    "ins_to_use = []\n",
    "ins_list = dict()\n",
    "\n",
    "instance = open(file, 'r')\n",
    "head = [next(instance) for x in range(4)]\n",
    "name = head[0].replace('\\n', '').split('-')\n",
    "road_map_code = name[1]\n",
    "if road_map_code == 'bj5':\n",
    "    road_map = 'Beijing'\n",
    "elif road_map_code == 'cd1':\n",
    "    road_map = 'Chengdu'\n",
    "else:\n",
    "    road_map = 'Manhattan'\n",
    "capacity = name[3].replace('c', '')\n",
    "v_num = head[2].replace('\\n', '').split(' ')[1]\n",
    "r_num = head[3].replace('\\n', '').split(' ')[1]\n",
    "ins_index = road_map_code + '-' + v_num + '-' + r_num\n",
    "if ins_index in ins_list.keys():\n",
    "    ins_list[ins_index].append(capacity)\n",
    "else:\n",
    "    ins_list[ins_index] = [capacity]\n",
    "    \n",
    "inst = pd.read_csv(file, skiprows = lambda x: x in range(6), sep = '\\t', header=None)\n",
    "inst.columns = ['id', 's', 't', 'Q', 'time_s', 'time_t']\n",
    "inst.head(5)\n",
    "v_id = np.where(inst['Q'] < 0)[0][:10]\n",
    "r_id = np.where(inst['Q'] > 0)[0]\n",
    "count = 0\n",
    "for i in range(10, 40, 10):  \n",
    "    for tp in [1, 3, 9]:\n",
    "        count += 1\n",
    "        re_info = open(re_path + 'instance-info_'+ str(count) + '.txt', 'w')\n",
    "        re_vehicles = re_path + 'instance_'+ str(count) + '-vehicles.csv'\n",
    "        re_riders = re_path + 'instance_'+ str(count) + '-riders.csv'\n",
    "        \n",
    "        tmp_r_id = r_id[:i]\n",
    "        data = {\n",
    "            \"index\": inst.iloc[tmp_r_id]['id'] - r_id[0],\n",
    "            \"s\": inst.iloc[tmp_r_id]['s'],\n",
    "            \"t\": inst.iloc[tmp_r_id]['t'],\n",
    "            \"et\": inst.iloc[tmp_r_id]['time_s']\n",
    "        }\n",
    "        riders = pd.DataFrame(data=data)\n",
    "        riders.to_csv(re_riders, index=False)\n",
    "        \n",
    "        if tp == 'random_types':\n",
    "            v_types = np.random.choice([1,3,6,9,30,60], len(v_id))\n",
    "        else:\n",
    "            v_types = np.full([len(v_id),], tp)\n",
    "    \n",
    "        data = {\n",
    "            \"index\": inst.iloc[v_id]['id'],\n",
    "            \"s\": inst.iloc[v_id]['s'],\n",
    "            \"t\": inst.iloc[v_id]['s'], # since this data set does not set destination for vehicles, we assume they return to s\n",
    "            \"p\": v_types,\n",
    "            \"e\": list(map(lambda x: vehicle_types[x]['emission'], v_types)),\n",
    "            \"c\": list(map(lambda x: vehicle_types[x]['cost'], v_types))\n",
    "        }\n",
    "        vehicles = pd.DataFrame(data=data)\n",
    "        vehicles.to_csv(re_vehicles, index=False)\n",
    "    \n",
    "        info = road_map_code + '.edges\\n' + re_riders + '\\t' + str(i) + '\\n' + re_vehicles + '\\t' + str(len(v_id)) + '\\n' + 'capacity:\\t' + capacity + '\\n' + 'original_instance:\\t' + file\n",
    "        re_info.write(info)\n",
    "        re_info.close()\n",
    "        \n",
    "        ins_info = str(count) + ',' + road_map_code + ',' + str(i) + ',' + str(len(v_id)) + ',' + str(tp)\n",
    "        print(ins_info)\n",
    "\n",
    "instance.close()    \n",
    "# ins_to_use is the instances file for our experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ace246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect information about all instances\n",
    "pre_path = 'original_instances/'\n",
    "re_path = 'instances_sizecontrol/'\n",
    "folders = os.listdir(pre_path)\n",
    "folders.sort()\n",
    "count = 0\n",
    "ins_col = []\n",
    "ins_to_use = []\n",
    "ins_list = dict()\n",
    "for a_ins in folders:\n",
    "    fre = a_ins.split('-')[-1].split('.')[0]\n",
    "    inst = a_ins.replace('d6','').replace('d12','').replace('d24','')\n",
    "    if inst in ins_col:\n",
    "        continue\n",
    "    count += 1\n",
    "    ins_col.append(inst)\n",
    "    ins_to_use.append(a_ins)\n",
    "    \n",
    "    file = pre_path + a_ins\n",
    "    instance = open(file, 'r')\n",
    "    head = [next(instance) for x in range(4)]\n",
    "    name = head[0].replace('\\n', '').split('-')\n",
    "    road_map_code = name[1]\n",
    "    if road_map_code == 'bj5':\n",
    "        road_map = 'Beijing'\n",
    "    elif road_map_code == 'cd1':\n",
    "        road_map = 'Chengdu'\n",
    "    else:\n",
    "        road_map = 'Manhattan'\n",
    "    capacity = name[3].replace('c', '')\n",
    "    v_num = head[2].replace('\\n', '').split(' ')[1]\n",
    "    r_num = head[3].replace('\\n', '').split(' ')[1]\n",
    "    ins_index = road_map_code + '-' + v_num + '-' + r_num\n",
    "    if ins_index in ins_list.keys():\n",
    "        ins_list[ins_index].append(capacity)\n",
    "    else:\n",
    "        ins_list[ins_index] = [capacity]\n",
    "    \n",
    "    inst = pd.read_csv(file, skiprows = lambda x: x in range(6), sep = '\\t', header=None)\n",
    "    inst.columns = ['id', 's', 't', 'Q', 'time_s', 'time_t']\n",
    "    inst.head(5)\n",
    "    v_id = np.where(inst['Q'] < 0)[0]\n",
    "    r_id = np.where(inst['Q'] > 0)[0]\n",
    "    #print(\"Number of vehicles: \", len(v_id))\n",
    "    #print(\"Number of riders: \", len(r_id))\n",
    "    \n",
    "    re_info = open(re_path + 'instance-info_'+ str(count) + '.txt', 'w')\n",
    "    re_vehicles = re_path + 'instance_'+ str(count) + '-vehicles.csv'\n",
    "    re_riders = re_path + 'instance_'+ str(count) + '-riders.csv'\n",
    "    \n",
    "    data = {\n",
    "        \"index\": inst.iloc[r_id]['id'] - r_id[0],\n",
    "        \"s\": inst.iloc[r_id]['s'],\n",
    "        \"t\": inst.iloc[r_id]['t'],\n",
    "        \"et\": inst.iloc[r_id]['time_s']\n",
    "    }\n",
    "    riders = pd.DataFrame(data=data)\n",
    "    riders.to_csv(re_riders, index=False)\n",
    "    \n",
    "    data = {\n",
    "        \"index\": inst.iloc[v_id]['id'],\n",
    "        \"s\": inst.iloc[v_id]['s'],\n",
    "        \"t\": inst.iloc[v_id]['s'], # since this data set does not set destination for vehicles, we assume they return to s\n",
    "        \"p\": 0 - inst.iloc[v_id]['Q'],\n",
    "        \"e\": list(map(lambda x: vehicle_types[0-x]['emission'], inst.iloc[v_id]['Q'])),\n",
    "        \"c\": list(map(lambda x: vehicle_types[0-x]['cost'], inst.iloc[v_id]['Q']))\n",
    "    }\n",
    "    vehicles = pd.DataFrame(data=data)\n",
    "    vehicles.to_csv(re_vehicles, index=False)\n",
    "    \n",
    "    info = road_map_code + '.edges\\n' + re_riders + '\\t' + r_num + '\\n' + re_vehicles + '\\t' + v_num + '\\n' + 'capacity:\\t' + capacity + '\\n' + 'original_instance:\\t' + file\n",
    "    re_info.write(info)\n",
    "    re_info.close()\n",
    "\n",
    "# ins_to_use is the instances file for our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ebbe7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate that vehicles are different types\n",
    "count = 99\n",
    "ins_extra = dict()\n",
    "for a_ins in ins_to_use:\n",
    "    file = pre_path + a_ins\n",
    "    road_map_code = a_ins.split('-')[1]\n",
    "    \n",
    "    instance = open(file, 'r')\n",
    "    head = [next(instance) for x in range(4)]\n",
    "    road_map_code = head[1].split(' ')[0]\n",
    "    v_num = head[2].replace('\\n', '').split(' ')[1]\n",
    "    r_num = head[3].replace('\\n', '').split(' ')[1]\n",
    "    ins_index = road_map_code + '-' + v_num + '-' + r_num\n",
    "    if ins_index in ins_extra.keys():\n",
    "        continue\n",
    "    else:\n",
    "        ins_list[ins_index].append('mix')\n",
    "        ins_extra[ins_index] = True\n",
    "    \n",
    "    count += 1\n",
    "    inst = pd.read_csv(file, skiprows = lambda x: x in range(6), sep = '\\t', header=None)\n",
    "    inst.columns = ['id', 's', 't', 'Q', 'time_s', 'time_t']\n",
    "    inst.head(5)\n",
    "    v_id = np.where(inst['Q'] < 0)[0]\n",
    "    r_id = np.where(inst['Q'] > 0)[0]\n",
    "    \n",
    "    re_info = open(re_path + 'instance-info_'+ str(count) + '.txt', 'w')\n",
    "    re_vehicles = re_path + 'instance_'+ str(count) + '-vehicles.csv'\n",
    "    re_riders = re_path + 'instance_'+ str(count) + '-riders.csv'\n",
    "    \n",
    "    data = {\n",
    "        \"index\": inst.iloc[r_id]['id'] - r_id[0],\n",
    "        \"s\": inst.iloc[r_id]['s'],\n",
    "        \"t\": inst.iloc[r_id]['t'],\n",
    "        \"et\": inst.iloc[r_id]['time_s']\n",
    "    }\n",
    "    riders = pd.DataFrame(data=data)\n",
    "    riders.to_csv(re_riders, index=False)\n",
    "    \n",
    "    v_id = np.where(inst['Q'] < 0)[0]\n",
    "    random_types = np.random.choice([1,3,6,9,30,60], len(v_id))\n",
    "    \n",
    "    data = {\n",
    "        \"index\": inst.iloc[v_id]['id'],\n",
    "        \"s\": inst.iloc[v_id]['s'],\n",
    "        \"t\": inst.iloc[v_id]['s'], # since this data set does not set destination for vehicles, we assume they return to s\n",
    "        \"p\": random_types,\n",
    "        \"e\": list(map(lambda x: vehicle_types[x]['emission'], random_types)),\n",
    "        \"c\": list(map(lambda x: vehicle_types[x]['cost'], random_types))\n",
    "    }\n",
    "    vehicles = pd.DataFrame(data=data)\n",
    "    vehicles.to_csv(re_vehicles, index=False)\n",
    "    \n",
    "    info = road_map_code + '.edges\\n' + re_riders + '\\t' + r_num + '\\n' + re_vehicles + '\\t' + v_num + '\\n' + 'capacity:\\t random_mix' + '\\n' + 'original_instance:\\t' + file\n",
    "    re_info.write(info)\n",
    "    re_info.close()\n",
    "    \n",
    "# ins_to_use is the instances file for our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6139231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,bj5.edges,17467,10000,1\n",
      "2,bj5.edges,17467,10000,3\n",
      "3,bj5.edges,8754,10000,3\n",
      "4,bj5.edges,34152,10000,3\n",
      "5,bj5.edges,65500,10000,3\n",
      "6,bj5.edges,17467,10000,6\n",
      "7,bj5.edges,17467,10000,8\n",
      "8,bj5.edges,17467,15000,1\n",
      "9,bj5.edges,17467,15000,3\n",
      "10,bj5.edges,8754,15000,3\n",
      "11,bj5.edges,34152,15000,3\n",
      "12,bj5.edges,65500,15000,3\n",
      "13,bj5.edges,17467,15000,6\n",
      "14,bj5.edges,17467,15000,8\n",
      "15,bj5.edges,17467,1000,1\n",
      "16,bj5.edges,17467,1000,3\n",
      "17,bj5.edges,8754,1000,3\n",
      "18,bj5.edges,34152,1000,3\n",
      "19,bj5.edges,65500,1000,3\n",
      "20,bj5.edges,17467,1000,6\n",
      "21,bj5.edges,17467,1000,8\n",
      "22,bj5.edges,17467,20000,1\n",
      "23,bj5.edges,17467,20000,3\n",
      "24,bj5.edges,8754,20000,3\n",
      "25,bj5.edges,34152,20000,3\n",
      "26,bj5.edges,65500,20000,3\n",
      "27,bj5.edges,17467,20000,6\n",
      "28,bj5.edges,17467,20000,8\n",
      "29,bj5.edges,17467,25000,1\n",
      "30,bj5.edges,17467,25000,3\n",
      "31,bj5.edges,8754,25000,3\n",
      "32,bj5.edges,34152,25000,3\n",
      "33,bj5.edges,65500,25000,3\n",
      "34,bj5.edges,17467,25000,6\n",
      "35,bj5.edges,17467,25000,8\n",
      "36,bj5.edges,17467,30000,1\n",
      "37,bj5.edges,17467,30000,3\n",
      "38,bj5.edges,8754,30000,3\n",
      "39,bj5.edges,34152,30000,3\n",
      "40,bj5.edges,65500,30000,3\n",
      "41,bj5.edges,17467,30000,6\n",
      "42,bj5.edges,17467,30000,8\n",
      "43,bj5.edges,17467,35000,1\n",
      "44,bj5.edges,17467,35000,3\n",
      "45,bj5.edges,8754,35000,3\n",
      "46,bj5.edges,34152,35000,3\n",
      "47,bj5.edges,65500,35000,3\n",
      "48,bj5.edges,17467,35000,6\n",
      "49,bj5.edges,17467,35000,8\n",
      "50,bj5.edges,17467,40000,1\n",
      "51,bj5.edges,17467,40000,3\n",
      "52,bj5.edges,8754,40000,3\n",
      "53,bj5.edges,34152,40000,3\n",
      "54,bj5.edges,65500,40000,3\n",
      "55,bj5.edges,17467,40000,6\n",
      "56,bj5.edges,17467,40000,8\n",
      "57,bj5.edges,17467,45000,1\n",
      "58,bj5.edges,17467,45000,3\n",
      "59,bj5.edges,8754,45000,3\n",
      "60,bj5.edges,34152,45000,3\n",
      "61,bj5.edges,65500,45000,3\n",
      "62,bj5.edges,17467,45000,6\n",
      "63,bj5.edges,17467,45000,8\n",
      "64,bj5.edges,17467,50000,1\n",
      "65,bj5.edges,17467,50000,3\n",
      "66,bj5.edges,8754,50000,3\n",
      "67,bj5.edges,34152,50000,3\n",
      "68,bj5.edges,65500,50000,3\n",
      "69,bj5.edges,17467,50000,6\n",
      "70,bj5.edges,17467,50000,8\n",
      "71,bj5.edges,17467,5000,1\n",
      "72,bj5.edges,17467,5000,3\n",
      "73,bj5.edges,8754,5000,3\n",
      "74,bj5.edges,34152,5000,3\n",
      "75,bj5.edges,65500,5000,3\n",
      "76,bj5.edges,17467,5000,6\n",
      "77,bj5.edges,17467,5000,8\n",
      "78,cd1.edges,8922,10000,3\n",
      "79,cd1.edges,8922,15000,3\n",
      "80,cd1.edges,8922,1000,3\n",
      "81,cd1.edges,8922,20000,3\n",
      "82,cd1.edges,8922,25000,3\n",
      "83,cd1.edges,8922,30000,3\n",
      "84,cd1.edges,8922,35000,3\n",
      "85,cd1.edges,8922,40000,3\n",
      "86,cd1.edges,8922,45000,3\n",
      "87,cd1.edges,8922,50000,3\n",
      "88,cd1.edges,8922,5000,3\n",
      "89,mny.edges,5033,10000,3\n",
      "90,mny.edges,5033,15000,3\n",
      "91,mny.edges,5033,1000,3\n",
      "92,mny.edges,5033,20000,3\n",
      "93,mny.edges,5033,25000,3\n",
      "94,mny.edges,5033,30000,3\n",
      "95,mny.edges,5033,35000,3\n",
      "96,mny.edges,5033,40000,3\n",
      "97,mny.edges,5033,45000,3\n",
      "98,mny.edges,5033,50000,3\n",
      "99,mny.edges,5033,5000,3\n",
      "100,bj5.edges,17467,10000, random_mix\n",
      "101,bj5.edges,8754,10000, random_mix\n",
      "102,bj5.edges,34152,10000, random_mix\n",
      "103,bj5.edges,65500,10000, random_mix\n",
      "104,bj5.edges,17467,15000, random_mix\n",
      "105,bj5.edges,8754,15000, random_mix\n",
      "106,bj5.edges,34152,15000, random_mix\n",
      "107,bj5.edges,65500,15000, random_mix\n",
      "108,bj5.edges,17467,1000, random_mix\n",
      "109,bj5.edges,8754,1000, random_mix\n",
      "110,bj5.edges,34152,1000, random_mix\n",
      "111,bj5.edges,65500,1000, random_mix\n",
      "112,bj5.edges,17467,20000, random_mix\n",
      "113,bj5.edges,8754,20000, random_mix\n",
      "114,bj5.edges,34152,20000, random_mix\n",
      "115,bj5.edges,65500,20000, random_mix\n",
      "116,bj5.edges,17467,25000, random_mix\n",
      "117,bj5.edges,8754,25000, random_mix\n",
      "118,bj5.edges,34152,25000, random_mix\n",
      "119,bj5.edges,65500,25000, random_mix\n",
      "120,bj5.edges,17467,30000, random_mix\n",
      "121,bj5.edges,8754,30000, random_mix\n",
      "122,bj5.edges,34152,30000, random_mix\n",
      "123,bj5.edges,65500,30000, random_mix\n",
      "124,bj5.edges,17467,35000, random_mix\n",
      "125,bj5.edges,8754,35000, random_mix\n",
      "126,bj5.edges,34152,35000, random_mix\n",
      "127,bj5.edges,65500,35000, random_mix\n",
      "128,bj5.edges,17467,40000, random_mix\n",
      "129,bj5.edges,8754,40000, random_mix\n",
      "130,bj5.edges,34152,40000, random_mix\n",
      "131,bj5.edges,65500,40000, random_mix\n",
      "132,bj5.edges,17467,45000, random_mix\n",
      "133,bj5.edges,8754,45000, random_mix\n",
      "134,bj5.edges,34152,45000, random_mix\n",
      "135,bj5.edges,65500,45000, random_mix\n",
      "136,bj5.edges,17467,50000, random_mix\n",
      "137,bj5.edges,8754,50000, random_mix\n",
      "138,bj5.edges,34152,50000, random_mix\n",
      "139,bj5.edges,65500,50000, random_mix\n",
      "140,bj5.edges,17467,5000, random_mix\n",
      "141,bj5.edges,8754,5000, random_mix\n",
      "142,bj5.edges,34152,5000, random_mix\n",
      "143,bj5.edges,65500,5000, random_mix\n",
      "144,cd1.edges,8922,10000, random_mix\n",
      "145,cd1.edges,8922,15000, random_mix\n",
      "146,cd1.edges,8922,1000, random_mix\n",
      "147,cd1.edges,8922,20000, random_mix\n",
      "148,cd1.edges,8922,25000, random_mix\n",
      "149,cd1.edges,8922,30000, random_mix\n",
      "150,cd1.edges,8922,35000, random_mix\n",
      "151,cd1.edges,8922,40000, random_mix\n",
      "152,cd1.edges,8922,45000, random_mix\n",
      "153,cd1.edges,8922,50000, random_mix\n",
      "154,cd1.edges,8922,5000, random_mix\n",
      "155,mny.edges,5033,10000, random_mix\n",
      "156,mny.edges,5033,15000, random_mix\n",
      "157,mny.edges,5033,1000, random_mix\n",
      "158,mny.edges,5033,20000, random_mix\n",
      "159,mny.edges,5033,25000, random_mix\n",
      "160,mny.edges,5033,30000, random_mix\n",
      "161,mny.edges,5033,35000, random_mix\n",
      "162,mny.edges,5033,40000, random_mix\n",
      "163,mny.edges,5033,45000, random_mix\n",
      "164,mny.edges,5033,50000, random_mix\n"
     ]
    }
   ],
   "source": [
    "instances_dict = dict()\n",
    "for file in os.listdir(\"datasets/info/\"):\n",
    "    if '.txt' not in file:\n",
    "        continue\n",
    "    index = file.split('_')[1].replace('.txt', '')\n",
    "    f = open(\"datasets/info/\" + file, 'r')\n",
    "    info_text = [next(f) for x in range(4)]\n",
    "    road_map = info_text[0].replace('\\n', '')\n",
    "    n_vehicles = info_text[1].replace('\\n', '').split('\\t')[1]\n",
    "    n_riders = info_text[2].replace('\\n', '').split('\\t')[1]\n",
    "    cap = info_text[3].replace('\\n', '').split('\\t')[1]\n",
    "    if '9' in cap:\n",
    "        cap = 8\n",
    "    instances_dict[int(index)] = index + ',' + road_map + ',' + n_vehicles + ',' + n_riders + ',' + str(cap)\n",
    "    \n",
    "for key in sorted(instances_dict):\n",
    "    print(instances_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_i = 0\n",
    "for key, value in ins_list.items():\n",
    "    info = key.split('-')\n",
    "    road_map_code = info[0]\n",
    "    if road_map_code == 'bj5':\n",
    "        road_map = 'Beijing'\n",
    "    elif road_map_code == 'cd1':\n",
    "        road_map = 'Chengdu'\n",
    "    else:\n",
    "        road_map = 'Manhattan'\n",
    "    a_row = road_map + ' & ' + info[1] + ' & ' + info[2]\n",
    "    num_i += len(value)\n",
    "    a_row = a_row + ' & ' + str(value)\n",
    "    print(a_row)\n",
    "print(count)\n",
    "print(num_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bcef944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_riders(f_name):\n",
    "    riders = pd.read_csv(f_name, sep= \",\", header= 0, index_col= False)\n",
    "    riders.columns=[\"index\", \"s\", \"t\", \"et\"]\n",
    "    return riders\n",
    "\n",
    "riders = load_riders('instances/instance_1-riders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5f90a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>p</th>\n",
       "      <th>e</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32306</td>\n",
       "      <td>32306</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.29411765 0.52941176 0.71470588]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>98601</td>\n",
       "      <td>98601</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.29411765 0.52941176 0.71470588]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>143505</td>\n",
       "      <td>143505</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.29411765 0.52941176 0.71470588]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       s       t  p                                   e  c\n",
       "0      1   32306   32306  3  [0.29411765 0.52941176 0.71470588]  3\n",
       "1      2   98601   98601  3  [0.29411765 0.52941176 0.71470588]  3\n",
       "2      3  143505  143505  3  [0.29411765 0.52941176 0.71470588]  3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_vehicles(f_name):\n",
    "    vehicles = pd.read_csv(f_name, sep= \",\", header= 0, index_col= False)\n",
    "    vehicles.columns=[\"index\",\"s\",\"t\", \"p\", \"e\", \"c\"]\n",
    "    return vehicles\n",
    "\n",
    "vehicles = load_vehicles('instances/instance_3-vehicles.csv')\n",
    "vehicles.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
